{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import a TensorFlow model into IBM Watson Machine Learning\n",
    "\n",
    "Importing a model into Watson Machine Learning means to store a trained model in your Watson Machine Learning repository and then deploy the stored model.  This notebook demonstrates importing a TensorFlow model.\n",
    "\n",
    "See also: <a href=\"https://dataplatform.cloud.ibm.com/docs/content/analyze-data/ml-import-tensorflow.html\" target=\"_blank\" rel=\"noopener noreferrer\">Importing a TensorFlow model</a>\n",
    "\n",
    "This notebook runs on Python 3.5.\n",
    "\n",
    "\n",
    "### Notebook sections\n",
    "\n",
    "[Step 0: Build, train, and save a model](#step0)\n",
    "\n",
    "[Step 1: Store the model in your Watson Machine Learning repository](#step1)\n",
    "\n",
    "[Step 2: Deploy the stored modelin your Watson Machine Learning service](#step2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"step0\"></a> Step 0: Build, train, and save a model\n",
    "\n",
    "**About the sample model**\n",
    "\n",
    "The sample model built here classifies text messages from fictional customers into two categories:\n",
    "- \"social\" : The message might just be social and friendly, or the message lacks enough text to perform in-depth analysis\n",
    "- \"problem or question\" : The message describes a prob1em or asks a questions\n",
    "\n",
    "Classifying messages this way is useful for multiple purposes:\n",
    "- Automating responses (eg. respond to social messages with a generial greeting, prompting the user to type their question or problem if they have one)\n",
    "- Cleaning out social message for post-hoc analysis\n",
    "\n",
    "\n",
    "The data used to train the model is the \"GoSales.csv\" training data in the IBM Watson Studio community: <a href=\"https://dataplatform.cloud.ibm.com/exchange/public/entry/view/015ddef6a868441188268a123404f744\" target=\"_blank\" rel=\"noopener noreferrer\">Customer messages sample data</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /Users/jinsalex/anaconda3/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wget # Needed to download sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample-customer-messages.csv\n"
     ]
    }
   ],
   "source": [
    "# Download sample training data to the notebook working directory and read it into a Pandas DataFrame\n",
    "import wget\n",
    "training_data_url = 'https://dataplatform.cloud.ibm.com/data/exchange-api/v1/entries/015ddef6a868441188268a123404f744/data?accessKey=c8d0403d844a82df9ecd264df02f2b07'\n",
    "filename = wget.download( training_data_url )\n",
    "print( filename )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Greetings :)</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hai how can i do analyze with csv file is ther...</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Having issues setup WML service</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message class_name\n",
       "6                                       Greetings :)         hi\n",
       "7  hai how can i do analyze with csv file is ther...   question\n",
       "8                    Having issues setup WML service    problem"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read sample data into Pandas DataFrame\n",
    "import pandas as pd\n",
    "df = pd.read_csv( filename, names=[ \"message\", \"class_name\" ] )\n",
    "df[6:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split( df, test_size = 0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vocabulary containing the words in the training data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit( train[\"message\"] )\n",
    "vocab_size = len( vectorizer.get_feature_names() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 276\n",
      "\n",
      "['5gb', 'able', 'access', 'account', 'accout', 'acess', 'active', 'add', 'am', 'an'] ...\n"
     ]
    }
   ],
   "source": [
    "print( \"vocab_size: \"+ str( vocab_size) )\n",
    "print( \"\\n\" + str( vectorizer.get_feature_names()[0:10] ) + \" ...\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the messages to vectors\n",
    "X_train = vectorizer.transform( train[\"message\"] ).toarray()\n",
    "X_test  = vectorizer.transform( test[\"message\" ] ).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Hi I would like to signup for a trail but I am...</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good morning</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>hey there</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>I get error like Exceeded Services Limit</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Hi there can i recover a deleted notebook?</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Hi I am trying to Import Github Code To Create...</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hello... i created a Cloudent NoSQL DB and loa...</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>How do I add collaborators to my project please?</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good evening</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>hi is there link on how to deploy a data analy...</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              message class_name\n",
       "58  Hi I would like to signup for a trail but I am...    problem\n",
       "2                                        Good morning         hi\n",
       "30                                          hey there         hi\n",
       "88           I get error like Exceeded Services Limit    problem\n",
       "71         Hi there can i recover a deleted notebook?   question\n",
       "46  Hi I am trying to Import Github Code To Create...    problem\n",
       "28  Hello... i created a Cloudent NoSQL DB and loa...   question\n",
       "77   How do I add collaborators to my project please?   question\n",
       "1                                        Good evening         hi\n",
       "63  hi is there link on how to deploy a data analy...   question"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print( X_test[0:1,:] )\n",
    "print( X_test[1:2,:] )\n",
    "print( X_test[2:3,:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the labels to binary labels\n",
    "import scipy\n",
    "import numpy as np\n",
    "y_train = np.array( [ [ 1, 0 ] if class_name == \"hi\" else [ 0, 1 ] for class_name in train[ \"class_name\" ] ] )\n",
    "y_test  = np.array( [ [ 1, 0 ] if class_name == \"hi\" else [ 0, 1 ] for class_name in test[ \"class_name\" ] ] )\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinsalex/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jinsalex/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:691: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "num_inputs         = vocab_size\n",
    "num_layer1_nodes   = 50\n",
    "num_output_classes = 2\n",
    "learning_rate      = 0.01\n",
    "\n",
    "#Input: X, labels: y\n",
    "X = tf.placeholder( tf.float32, shape = ( None, num_inputs ) )\n",
    "y = tf.placeholder( tf.float32, shape = ( None, num_output_classes ) )\n",
    "\n",
    "# Layer 1\n",
    "w1 = tf.Variable( tf.truncated_normal( shape=[ num_inputs, num_layer1_nodes ] ) )\n",
    "b1 = tf.Variable( tf.zeros( shape=[ num_layer1_nodes ] ) )\n",
    "layer1_output =  tf.nn.relu( tf.matmul( X, w1 ) +  b1 ) \n",
    "\n",
    "# Output\n",
    "w2 = tf.Variable( tf.truncated_normal( shape=[ num_layer1_nodes, num_output_classes ] ) )\n",
    "b2 = tf.Variable( tf.zeros( shape=[ num_output_classes ] ) )\n",
    "output = tf.nn.softmax( tf.matmul( layer1_output, w2 ) + b2 )\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy( y, output )\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer( learning_rate ).minimize( loss )\n",
    "\n",
    "expected_result = tf.argmax( y,      axis = 1 )\n",
    "classification  = tf.argmax( output, axis = 1 )\n",
    "accuracy = tf.reduce_mean( tf.cast( tf.equal( expected_result, classification ), tf.float32 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "session.run( tf.global_variables_initializer() )\n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_test  = []\n",
    "\n",
    "for epoch in range( num_epochs ):\n",
    "    \n",
    "    session.run( optimizer, feed_dict={ X : X_train, y : y_train } )\n",
    "    \n",
    "    accuracy_train.append( session.run( accuracy, feed_dict = { X : X_train, y : y_train } ) )\n",
    "    accuracy_test.append(  session.run( accuracy, feed_dict = { X : X_test, y  : y_test  } ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use( \"seaborn-white\" )\n",
    "\n",
    "plt.title(  \"Accuracy\", fontsize = 18)\n",
    "\n",
    "x = range( 1, num_epochs + 1 )\n",
    "plt.plot( x, accuracy_train, label = \"Training\" )\n",
    "plt.plot( x, accuracy_test,  label = \"Test\" )\n",
    "\n",
    "legend = plt.legend( loc=\"upper left\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Hi I would like to signup for a trail but I am...</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good morning</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>hey there</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>I get error like Exceeded Services Limit</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Hi there can i recover a deleted notebook?</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Hi I am trying to Import Github Code To Create...</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hello... i created a Cloudent NoSQL DB and loa...</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>How do I add collaborators to my project please?</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good evening</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>hi is there link on how to deploy a data analy...</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              message class_name\n",
       "58  Hi I would like to signup for a trail but I am...    problem\n",
       "2                                        Good morning         hi\n",
       "30                                          hey there         hi\n",
       "88           I get error like Exceeded Services Limit    problem\n",
       "71         Hi there can i recover a deleted notebook?   question\n",
       "46  Hi I am trying to Import Github Code To Create...    problem\n",
       "28  Hello... i created a Cloudent NoSQL DB and loa...   question\n",
       "77   How do I add collaborators to my project please?   question\n",
       "1                                        Good evening         hi\n",
       "63  hi is there link on how to deploy a data analy...   question"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "test_results = session.run( classification, feed_dict = { X : X_test } )\n",
    "print( test_results )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "You can import your TensorFlow model into Watson Machine Learning in two formats:\n",
    "- Model saved in a directory using <a href=\"https://www.tensorflow.org/guide/saved_model#save_and_restore_models\" target=\"_blank\" rel=\"noopener noreferrer\">saved_model</a>\n",
    "- Model saved in a tar.gz file\n",
    "\n",
    "In this section of the notebook, the model is saved in a dictionary, and the ditionary is saved in a tar.gz file to demonstrate both options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_inputs         = tf.saved_model.utils.build_tensor_info( X )\n",
    "classification_output_classes = tf.saved_model.utils.build_tensor_info( classification )\n",
    "\n",
    "classification_signature = ( tf.saved_model.signature_def_utils.build_signature_def (\n",
    "    inputs  = { tf.saved_model.signature_constants.CLASSIFY_INPUTS         : classification_inputs },\n",
    "    outputs = { tf.saved_model.signature_constants.CLASSIFY_OUTPUT_CLASSES : classification_output_classes },\n",
    "    method_name=tf.saved_model.signature_constants.CLASSIFY_METHOD_NAME ) )\n",
    "\n",
    "#print( classification_signature )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'message-classification-model-dir/saved_model.pb'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'message-classification-model-dir/saved_model.pb'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model in a directory\n",
    "builder = tf.saved_model.builder.SavedModelBuilder( \"message-classification-model-dir\" )\n",
    "\n",
    "builder.add_meta_graph_and_variables(\n",
    "      session, [ tf.saved_model.tag_constants.SERVING ],\n",
    "      signature_def_map={ \"classify_message\" : classification_signature, },\n",
    "      main_op=tf.tables_initializer() )\n",
    "\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 136\n",
      "-rw-r--r--  1 jinsalex  staff  68351 Jun 12 11:25 saved_model.pb\n",
      "drwxr-xr-x  4 jinsalex  staff    128 Jun 12 11:25 \u001b[34mvariables\u001b[m\u001b[m\n",
      "total 336\n",
      "-rw-r--r--  1 jinsalex  staff  167432 Jun 12 11:25 variables.data-00000-of-00001\n",
      "-rw-r--r--  1 jinsalex  staff     496 Jun 12 11:25 variables.index\n"
     ]
    }
   ],
   "source": [
    "!ls -l message-classification-model-dir\n",
    "!ls -l message-classification-model-dir/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a .\r\n",
      "a ./variables\r\n",
      "a ./saved_model.pb\r\n",
      "a ./variables/variables.data-00000-of-00001\r\n",
      "a ./variables/variables.index\r\n"
     ]
    }
   ],
   "source": [
    "# Save the model in a tar.gz file\n",
    "!tar -zcvf message-classification-model.tar.gz -C message-classification-model-dir ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 336\r\n",
      "drwxr-xr-x  4 jinsalex  staff     128 Jun 12 11:25 \u001b[34mmessage-classification-model-dir\u001b[m\u001b[m\r\n",
      "-rw-r--r--  1 jinsalex  staff  111005 Jun 12 11:25 message-classification-model.tar.gz\r\n",
      "-rw-r--r--  1 jinsalex  staff    5781 Jun 12 11:25 sample-customer-messages.csv\r\n",
      "-rw-r--r--  1 jinsalex  staff   48664 Jun 11 15:50 tensorflow-import-python.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"step1\"></a> Step 1: Store the model in your Watson Machine Learning repository\n",
    "\n",
    "This section of the notebook demonstrates calling the <a href=\"https://wml-api-pyclient.mybluemix.net/index.html?highlight=store_model#client.Repository.store_model\" target=\"_blank\" rel=\"noopener noreferrer\">store_model</a> function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paste your Watson Machine Learning credentials in the following cell.\n",
    "\n",
    "See: <a href=\"https://dataplatform.cloud.ibm.com/docs/content/analyze-data/ml-get-wml-credentials.html\" target=\"_blank\" rel=\"noopener noreferrer\">Looking up credentials</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinsalex/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create a Watson Machine Learning client instance\n",
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "wml_credentials = {\n",
    "    \"apikey\"    : \"value\",\n",
    "    \"instance_id\" : \"instance_id\",\n",
    "    \"url\"    : \"url\"\n",
    "}\n",
    "client = WatsonMachineLearningAPIClient( wml_credentials )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format 1: Model saved in a directory\n",
    "#\n",
    "# Parameters:\n",
    "# 1. The directory where the model was saved\n",
    "# 2. Metadata, including a name you choose for the stored model, as well as information about the framework\n",
    "#\n",
    "metadata = {\n",
    "    client.repository.ModelMetaNames.NAME: \"TensorFlow model (directory)\",\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_NAME: \"tensorflow\",\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_VERSION: \"1.5\"\n",
    "}\n",
    "model_details_dir = client.repository.store_model( model=\"message-classification-model-dir\", meta_props=metadata )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format 2: Model saved in a directory, and that directory saved in a tar.gz file\n",
    "#\n",
    "# Parameters:\n",
    "# 1. The tar.gz file containing the directory where the model was saved\n",
    "# 2. Metadata, including a name you choose for the stored model, as well as information about the framework\n",
    "#\n",
    "metadata = {\n",
    "    client.repository.ModelMetaNames.NAME: \"TensorFlow model (tar.gz)\",\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_NAME: \"tensorflow\",\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_VERSION: \"1.5\"\n",
    "}\n",
    "model_details_targz = client.repository.store_model( model=\"message-classification-model.tar.gz\", meta_props=metadata )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"step2\"></a> Step 2: Deploy the stored the model in your Watson Machine Learning service\n",
    "\n",
    "This section of the notebook demonstrates calling the <a href=\"https://wml-api-pyclient.mybluemix.net/index.html?highlight=deploy#client.Deployments.create\" target=\"_blank\" rel=\"noopener noreferrer\">deployments.create</a> function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: '00abd83b-7461-40c6-a7a4-8663dfb3cb96' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "INITIALIZING\n",
      "DEPLOY_SUCCESS\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_uid='27bc1f41-0694-4377-a4d0-1567c61d76cc'\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Deploy the stored model as an online web service deployment\n",
    "model_id_dir = model_details_dir[\"metadata\"][\"guid\"]\n",
    "deployment_details_dir = client.deployments.create( artifact_uid=model_id_dir, name=\"TensorFlow deployment (directory)\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'values': [1, 0, 0, 0, 0, 1, 1, 1, 0, 1]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the deployment\n",
    "model_endpoint_url_dir = client.deployments.get_scoring_url( deployment_details_dir )\n",
    "payload = { \"values\" : X_test.tolist() }\n",
    "client.deployments.score( model_endpoint_url_dir, payload )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook, you imported a TensorFlow model into Watson Machine Learning using the Watson Machine Learning Python client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"authors\"></a>Authors\n",
    "\n",
    "**Sarah Packowski** is a member of the IBM Watson Studio Content Design team in Canada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr>\n",
    "Copyright &copy; IBM Corp. 2019. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n",
    "<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n",
    "<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
