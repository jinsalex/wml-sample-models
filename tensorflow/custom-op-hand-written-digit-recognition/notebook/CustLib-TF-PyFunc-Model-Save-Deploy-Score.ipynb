{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<body>\n",
    "    <table style=\"border: none\" align=\"center\">\n",
    "        <tr style=\"border: none\">\n",
    "            <th style=\"border: none\"><img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" alt=\"Watson Machine Learning icon\" height=\"45\" width=\"45\"></th>\n",
    "            <th style=\"border: none\"><font face=\"verdana\" size=\"6\" color=\"black\"><b>Watson Machine Learning</b></font></th>\n",
    "        </tr>\n",
    "    </table>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains steps and code to define a custom operation using tf.py_func operation in tensorflow. The custom operation is then used in a LeNet network for handwritten character recognition which is trained on the MNIST dataset. The trained model is persisted, deployed and scored using the Watson Machine Learning Service and the Watson Machine Learning Client.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python-3.5, numpy-1.14 and tensorflow-1.5.\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "The learning goals of this notebook are:\n",
    "\n",
    "-  Define a custom operation and corresponding gradient using `tf.py_func`\n",
    "-  Create a LeNet model using the defined custom operation\n",
    "-  Train the model on the MNIST dataset\n",
    "-  Create a library containing the custom tensor operation\n",
    "-  Persist the library and the model in Watson Machine Learning repository.\n",
    "-  Deploy the model using Watson Machine Learning Service\n",
    "-  Perform some classifications using the deployed model\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "1.  [Setup the environment](#setup)\n",
    "1.  [Create operation for tf.py_func and download library](#func)\n",
    "2.\t[Load data and initialize parameters](#load)\n",
    "3.\t[Create and train Lenet model](#model)\n",
    "4.  [Save model locally](#save)\n",
    "5.  [Persist library and runtime resource](#lib_persistence)\n",
    "6.\t[Persist Lenet model in Cloud](#persistence)\n",
    "7.  [Deploy and perform prediction on the Lenet model](#Scoring)\n",
    "8.  [Summary](#summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Set up the environment\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "-  Create a [Watson Machine Learning (WML) Service](https://console.bluemix.net/catalog/services/machine-learning) instance (a lite  plan is offered and information about how to create the instance is [here](https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html))\n",
    "- Configure your local python environment:\n",
    "  + python 3.5\n",
    "  + tensorflow 1.5\n",
    "  + watson-machine-learning-client, version: 1.0.293 or above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $PIP_BUILD/watson-machine-learning-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: watson-machine-learning-client in /Users/jinsalex/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already up-to-date: tqdm in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from watson-machine-learning-client)\n",
      "Requirement already up-to-date: urllib3 in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from watson-machine-learning-client)\n",
      "Requirement already up-to-date: lomond in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from watson-machine-learning-client)\n",
      "Requirement already up-to-date: pandas in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from watson-machine-learning-client)\n",
      "Requirement already up-to-date: certifi in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from watson-machine-learning-client)\n",
      "Requirement already up-to-date: requests in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from watson-machine-learning-client)\n",
      "Requirement already up-to-date: tabulate in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from watson-machine-learning-client)\n",
      "Requirement already up-to-date: ibm-cos-sdk in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from watson-machine-learning-client)\n",
      "Requirement already up-to-date: six>=1.10.0 in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from lomond->watson-machine-learning-client)\n",
      "Requirement already up-to-date: pytz>=2011k in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from pandas->watson-machine-learning-client)\n",
      "Requirement already up-to-date: numpy>=1.12.0 in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from pandas->watson-machine-learning-client)\n",
      "Requirement already up-to-date: python-dateutil>=2.5.0 in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from pandas->watson-machine-learning-client)\n",
      "Requirement already up-to-date: chardet<3.1.0,>=3.0.2 in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from requests->watson-machine-learning-client)\n",
      "Requirement already up-to-date: idna<2.9,>=2.5 in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from requests->watson-machine-learning-client)\n",
      "Requirement already up-to-date: ibm-cos-sdk-s3transfer==2.*,>=2.0.0 in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from ibm-cos-sdk->watson-machine-learning-client)\n",
      "Requirement already up-to-date: ibm-cos-sdk-core==2.*,>=2.0.0 in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from ibm-cos-sdk->watson-machine-learning-client)\n",
      "Requirement already up-to-date: jmespath<1.0.0,>=0.7.1 in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client)\n",
      "Requirement already up-to-date: docutils>=0.10 in /Users/jinsalex/anaconda3/lib/python3.6/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install watson-machine-learning-client --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"func\"></a>\n",
    "## 2. Create operation for tf.py_func and download library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create custom operation for tf.py_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While creating a custom operation for tf.py_func, it is also necessary to create the corresponding gradient function. Tensorflow maps any function passed to tf.py_func under the `PyFunc` operation type. Tensorflow models perform gradient calculation during training. Hence, a user defined `tf.py_func` operation requires a corresponding gradient function defined and mapped to the `PyFunc` operation type. In this example, `reshape_grad` is the gradient function for the `tf.py_func` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinsalex/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.framework import ops \n",
    "\n",
    "def reshape_func(x):\n",
    "    return x.reshape((-1, 28, 28, 1)) \n",
    "\n",
    "def reshape_grad(op, grad):\n",
    "    x = op.inputs[0]\n",
    "\n",
    "    return grad\n",
    "\n",
    "def create_py_func_with_grads(op, inp, tout, stateful=True, name=None, grad=None):\n",
    "    grad_name = 'PyFuncGrad' + str(np.random.randint(0, 1e+8))\n",
    "\n",
    "    tf.RegisterGradient(grad_name)(grad)\n",
    "    g = tf.get_default_graph()\n",
    "\n",
    "    with g.gradient_override_map({\"PyFunc\": grad_name}):\n",
    "        return tf.py_func(op, inp, tout, stateful=stateful, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Downloading library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to store and deploy models that use operations defined through `tf.py_func`, a python distributable library needs to be created. The library should contain an `initialize_py_func()` function which defines the `tf.py_func` operation. The operation defined within this function should have the same name as the operation created during model definition and training. Also, `initialize_py_func()` function must be referenceable using the top-level module name. For example, if top-level \n",
    "module in the python distribution package is `my_top_module`, then `initialize_py_func()` must be referenceable as \n",
    "`my_top_module.initialize_py_func()`.\n",
    "\n",
    "Currently, only source distributed libraries archived in `.zip` format are supported. Libraries distributions of type `wheels` and `eggs` are not supported\n",
    "\n",
    "Any 3rd party libraries that are required for the custom transformer must be defined as the dependency for the corresponding library that contains implementation of the transformer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we download the library `custom_reshape_pyfunc.zip` which defines the reshape operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-11 16:48:43--  https://github.com/pmservice/wml-sample-models/raw/master/tensorflow/custom-op-hand-written-digit-recognition/libraries/custom_reshape_pyfunc-0.1.zip\n",
      "Resolving github.com... 13.234.210.38\n",
      "Connecting to github.com|13.234.210.38|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/pmservice/wml-sample-models/master/tensorflow/custom-op-hand-written-digit-recognition/libraries/custom_reshape_pyfunc-0.1.zip [following]\n",
      "--2019-06-11 16:48:43--  https://raw.githubusercontent.com/pmservice/wml-sample-models/master/tensorflow/custom-op-hand-written-digit-recognition/libraries/custom_reshape_pyfunc-0.1.zip\n",
      "Resolving raw.githubusercontent.com... 151.101.36.133\n",
      "Connecting to raw.githubusercontent.com|151.101.36.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3138 (3.1K) [application/zip]\n",
      "Saving to: ‘custom_reshape_pyfunc.zip’\n",
      "\n",
      "custom_reshape_pyfu 100%[===================>]   3.06K  --.-KB/s    in 0s      \n",
      "\n",
      "2019-06-11 16:48:44 (22.7 MB/s) - ‘custom_reshape_pyfunc.zip’ saved [3138/3138]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/pmservice/wml-sample-models/raw/master/tensorflow/custom-op-hand-written-digit-recognition/libraries/custom_reshape_pyfunc-0.1.zip --output-document=custom_reshape_pyfunc.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "## 3. Load data and initialize parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the MNIST dataset from Yann LeCunn's homepage using the built-in tensorflow library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Training and network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 10000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784 \n",
    "n_classes = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "## 4. Create and train Lenet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining placeholders and the default layer configurations for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input], name=\"x_input\")\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `create_py_func_with_grads` function defines a `tf.py_func` operation along with the corresponding gradient and returns the resulting tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-2724e7721b0e>:34: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_trans1 = create_py_func_with_grads(reshape_func, [x], tf.float32, False, name='ReshapeFunc', grad=reshape_grad)\n",
    "\n",
    "# Convolution Layer -1\n",
    "x_conv2d_l1 = tf.nn.conv2d(x_trans1, weights['wc1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "x_w_bias_l1 = tf.nn.bias_add(x_conv2d_l1, biases['bc1'])\n",
    "x_relu_l1 = tf.nn.relu(x_w_bias_l1)\n",
    "conv1_out = tf.nn.max_pool(x_relu_l1,\n",
    "                           ksize=[1, 2, 2, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='SAME')\n",
    "\n",
    "\n",
    "# Convolution Layer -2\n",
    "x_conv2d_l2 = tf.nn.conv2d(conv1_out, weights['wc2'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "x_w_bias_l2 = tf.nn.bias_add(x_conv2d_l2, biases['bc2'])\n",
    "x_relu_l2 = tf.nn.relu(x_w_bias_l2)\n",
    "conv2_out = tf.nn.max_pool(x_relu_l2,\n",
    "                           ksize=[1, 2, 2, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='SAME')\n",
    "\n",
    "# Fully connected layer\n",
    "# Reshape conv2 output to fit fully connected layer input\n",
    "fc1 = tf.reshape(conv2_out, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "# Output, class prediction\n",
    "conv_out = tf.add(tf.matmul(fc1, weights['out']), biases['out'], name=\"output_tensor\")\n",
    "\n",
    "predictor = tf.argmax(conv_out, 1, name=\"predictor\")\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=conv_out, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# To Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(conv_out, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch iteration: 128\n",
      "Completed batch iteration: 256\n",
      "Completed batch iteration: 384\n",
      "Completed batch iteration: 512\n",
      "Completed batch iteration: 640\n",
      "Completed batch iteration: 768\n",
      "Completed batch iteration: 896\n",
      "Completed batch iteration: 1024\n",
      "Completed batch iteration: 1152\n",
      "Completed batch iteration: 1280\n",
      "Iter 1280, Minibatch Loss= 27310.554688, Training Accuracy= 0.23438\n",
      "Completed batch iteration: 1408\n",
      "Completed batch iteration: 1536\n",
      "Completed batch iteration: 1664\n",
      "Completed batch iteration: 1792\n",
      "Completed batch iteration: 1920\n",
      "Completed batch iteration: 2048\n",
      "Completed batch iteration: 2176\n",
      "Completed batch iteration: 2304\n",
      "Completed batch iteration: 2432\n",
      "Completed batch iteration: 2560\n",
      "Iter 2560, Minibatch Loss= 10731.765625, Training Accuracy= 0.49219\n",
      "Completed batch iteration: 2688\n",
      "Completed batch iteration: 2816\n",
      "Completed batch iteration: 2944\n",
      "Completed batch iteration: 3072\n",
      "Completed batch iteration: 3200\n",
      "Completed batch iteration: 3328\n",
      "Completed batch iteration: 3456\n",
      "Completed batch iteration: 3584\n",
      "Completed batch iteration: 3712\n",
      "Completed batch iteration: 3840\n",
      "Iter 3840, Minibatch Loss= 6020.161621, Training Accuracy= 0.65625\n",
      "Completed batch iteration: 3968\n",
      "Completed batch iteration: 4096\n",
      "Completed batch iteration: 4224\n",
      "Completed batch iteration: 4352\n",
      "Completed batch iteration: 4480\n",
      "Completed batch iteration: 4608\n",
      "Completed batch iteration: 4736\n",
      "Completed batch iteration: 4864\n",
      "Completed batch iteration: 4992\n",
      "Completed batch iteration: 5120\n",
      "Iter 5120, Minibatch Loss= 5005.339844, Training Accuracy= 0.71875\n",
      "Completed batch iteration: 5248\n",
      "Completed batch iteration: 5376\n",
      "Completed batch iteration: 5504\n",
      "Completed batch iteration: 5632\n",
      "Completed batch iteration: 5760\n",
      "Completed batch iteration: 5888\n",
      "Completed batch iteration: 6016\n",
      "Completed batch iteration: 6144\n",
      "Completed batch iteration: 6272\n",
      "Completed batch iteration: 6400\n",
      "Iter 6400, Minibatch Loss= 3284.541016, Training Accuracy= 0.72656\n",
      "Completed batch iteration: 6528\n",
      "Completed batch iteration: 6656\n",
      "Completed batch iteration: 6784\n",
      "Completed batch iteration: 6912\n",
      "Completed batch iteration: 7040\n",
      "Completed batch iteration: 7168\n",
      "Completed batch iteration: 7296\n",
      "Completed batch iteration: 7424\n",
      "Completed batch iteration: 7552\n",
      "Completed batch iteration: 7680\n",
      "Iter 7680, Minibatch Loss= 2586.976562, Training Accuracy= 0.82812\n",
      "Completed batch iteration: 7808\n",
      "Completed batch iteration: 7936\n",
      "Completed batch iteration: 8064\n",
      "Completed batch iteration: 8192\n",
      "Completed batch iteration: 8320\n",
      "Completed batch iteration: 8448\n",
      "Completed batch iteration: 8576\n",
      "Completed batch iteration: 8704\n",
      "Completed batch iteration: 8832\n",
      "Completed batch iteration: 8960\n",
      "Iter 8960, Minibatch Loss= 2643.512695, Training Accuracy= 0.80469\n",
      "Completed batch iteration: 9088\n",
      "Completed batch iteration: 9216\n",
      "Completed batch iteration: 9344\n",
      "Completed batch iteration: 9472\n",
      "Completed batch iteration: 9600\n",
      "Completed batch iteration: 9728\n",
      "Completed batch iteration: 9856\n",
      "Completed batch iteration: 9984\n",
      "Model training finished!\n"
     ]
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "step = 1\n",
    "# Keep training until reach max iterations\n",
    "while step * batch_size < training_iters:\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    # Run optimization op (backprop)\n",
    "    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "    print(\"Completed batch iteration: \" + str(step*batch_size) )\n",
    "    if step % display_step == 0:\n",
    "        # Calculate batch loss and accuracy\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "    \n",
    "        print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "              \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "              \"{:.5f}\".format(acc))\n",
    "    step += 1\n",
    "print(\"Model training finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"save\"></a>\n",
    "\n",
    "## 5. Save model locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Save model locally using SavedModelBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove previously created directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "save_path = './tf_model_mnist_test'\n",
    "# delete dir if directory exists\n",
    "if os.path.exists(save_path):\n",
    "    shutil.rmtree(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create SignatureDef metadata for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_signature content:\n",
      "inputs {\n",
      "  key: \"inputs\"\n",
      "  value {\n",
      "    name: \"x_input:0\"\n",
      "    dtype: DT_FLOAT\n",
      "    tensor_shape {\n",
      "      dim {\n",
      "        size: -1\n",
      "      }\n",
      "      dim {\n",
      "        size: 784\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  key: \"classes\"\n",
      "  value {\n",
      "    name: \"predictor:0\"\n",
      "    dtype: DT_INT64\n",
      "    tensor_shape {\n",
      "      dim {\n",
      "        size: -1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "method_name: \"tensorflow/serving/classify\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_inputs = tf.saved_model.utils.build_tensor_info(x)\n",
    "classification_outputs_classes = tf.saved_model.utils.build_tensor_info(predictor)\n",
    "\n",
    "classification_signature = (\n",
    "      tf.saved_model.signature_def_utils.build_signature_def(\n",
    "          inputs={\n",
    "              tf.saved_model.signature_constants.CLASSIFY_INPUTS:\n",
    "                  classification_inputs\n",
    "          },\n",
    "          outputs={\n",
    "              tf.saved_model.signature_constants.CLASSIFY_OUTPUT_CLASSES:\n",
    "                  classification_outputs_classes\n",
    "          },\n",
    "          method_name=tf.saved_model.signature_constants.CLASSIFY_METHOD_NAME))\n",
    "\n",
    "print(\"classification_signature content:\")\n",
    "print(classification_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the LeNet model locally using Tensorflow's SavedModelBuilder API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'./tf_model_mnist_test/saved_model.pb'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'./tf_model_mnist_test/saved_model.pb'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the signature_def_map.\n",
    "\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(save_path)\n",
    "legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
    "builder.add_meta_graph_and_variables(\n",
    "      sess, [tf.saved_model.tag_constants.SERVING],\n",
    "      signature_def_map={\n",
    "          'predict_images': classification_signature,\n",
    "      },\n",
    "      legacy_init_op=legacy_init_op)\n",
    "\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lib_persistence\"></a>\n",
    "## 6. Persist library and model in WML Repository\n",
    "\n",
    "\n",
    "In this section, using `watson_machine_learning_client`, you will ...\n",
    "- save the library `custom_reshape_pyfunc.zip` in WML Repository by creating a Library resource\n",
    "- create a Runtime resource and bind the Library resource to it. This Runtime resource will be used to configure the online deployment runtime environment for a model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the library as a library artifact in the WML repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticate to the Watson Machine Learning (WML) service on IBM Cloud.\n",
    "\n",
    "**Tip**: Authentication information (your credentials) can be found in the [Service credentials](https://console.bluemix.net/docs/services/service_credentials.html#service_credentials) tab of the service instance that you created on IBM Cloud. \n",
    "If there are no credentials listed for your instance in **Service credentials**, click **New credential (+)** and enter the information required to generate new authentication information. \n",
    "\n",
    "**Action**: Enter your WML service instance credentials here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials = {\n",
    "    \"apikey\"    : \"value\",\n",
    "    \"instance_id\" : \"instance_id\",\n",
    "    \"url\"    : \"url\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinsalex/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While creating the library metadata for storing the library in WML Repository, one must make sure that the value passed to `client.runtimes.LibraryMetaNames.NAME` key is the same as the value passed to the `name` parameter of `setup()` function in `setup.py` file which is used to build the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_lib_zip_path = \"custom_reshape_pyfunc.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_meta = {\n",
    "    client.runtimes.LibraryMetaNames.NAME: \"custom_reshape_pyfunc\",\n",
    "    client.runtimes.LibraryMetaNames.DESCRIPTION: \"A custom pyfunc lib which reshapes input\",\n",
    "    client.runtimes.LibraryMetaNames.FILEPATH: cust_lib_zip_path,\n",
    "    client.runtimes.LibraryMetaNames.VERSION: \"1.0\",\n",
    "    client.runtimes.LibraryMetaNames.PLATFORM: {\"name\": \"python\", \"versions\": [\"3.5\"]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_library_details = client.runtimes.store_library(lib_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_library_uid = client.runtimes.get_library_uid(custom_library_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aaca6566-bbb0-48c8-849d-46f7816021e8'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_library_uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving a Runtime Resource artifact in WML Repository\n",
    "The Runtime Resource Artifact contains references to a collection of all the custom libraries that need to be used together to deploy the concerned model.\n",
    "While creating the metadata to store the runtime artifact, pass a list of library uids that need to be used to the `client.runtimes.ConfigurationMetaNames.LIBRARIES_UIDS` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_meta = {\n",
    "    client.runtimes.ConfigurationMetaNames.NAME: 'runtime_mnist',\n",
    "    client.runtimes.ConfigurationMetaNames.DESCRIPTION: 'runtime spec - mnist',\n",
    "    client.runtimes.ConfigurationMetaNames.PLATFORM: {\n",
    "        \"name\": \"python\",\n",
    "        \"version\": \"3.5\"\n",
    "    },\n",
    "    client.runtimes.ConfigurationMetaNames.LIBRARIES_UIDS: [custom_library_uid]\n",
    "}\n",
    "runtime_details = client.runtimes.store(runtime_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity': {'content_url': 'https://us-south.ml.test.cloud.ibm.com/v4/runtimes/a78603bc-f708-417d-9461-5a66d086c6bd/content',\n",
       "  'custom_libraries': [{'name': 'custom_reshape_pyfunc',\n",
       "    'url': 'https://us-south.ml.test.cloud.ibm.com/v4/libraries/aaca6566-bbb0-48c8-849d-46f7816021e8',\n",
       "    'version': '1.0'}],\n",
       "  'description': 'runtime spec - mnist',\n",
       "  'name': 'runtime_mnist',\n",
       "  'platform': {'name': 'python', 'version': '3.5'}},\n",
       " 'metadata': {'created_at': '2019-06-11T11:19:31.576Z',\n",
       "  'guid': 'a78603bc-f708-417d-9461-5a66d086c6bd',\n",
       "  'url': 'https://us-south.ml.test.cloud.ibm.com/v4/runtimes/a78603bc-f708-417d-9461-5a66d086c6bd'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a78603bc-f708-417d-9461-5a66d086c6bd\n"
     ]
    }
   ],
   "source": [
    "custom_runtime_uid = client.runtimes.get_uid(runtime_details)\n",
    "print(custom_runtime_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"persistence\"></a>\n",
    "## 7. Persist Lenet model in Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model that needs to be saved in the repo needs to be of tar.gz format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we remove any existing model archive with the same name and then create a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('tf_mnist_pyfunc.tar.gz'):\n",
    "    os.remove('tf_mnist_pyfunc.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jinsalex/Armada_CI/Samples_Update/wml-sample-models/tensorflow/custom-op-hand-written-digit-recognition/notebook/tf_model_mnist_test\n"
     ]
    }
   ],
   "source": [
    "cd tf_model_mnist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_model.pb  \u001b[34mvariables\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a saved_model.pb\n",
      "a variables\n",
      "a variables/variables.data-00000-of-00001\n",
      "a variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "!tar -cvf ../tf_mnist_pyfunc.tar *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jinsalex/Armada_CI/Samples_Update/wml-sample-models/tensorflow/custom-op-hand-written-digit-recognition/notebook\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip tf_mnist_pyfunc.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'tf_mnist_pyfunc.tar.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model to WML Repository\n",
    "Bind Runtime resource to the model and save the model to WML Repository. <br>\n",
    "`client.repository.ModelMetaNames.RUNTIME_UID` key value pair is added to the model metadata as a reference to the runtime artifact which stores the list of library artifact urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-11 16:49:35,859 - watson_machine_learning_client.metanames - WARNING - 'AUTHOR_EMAIL' meta prop is deprecated. It will be ignored.\n"
     ]
    }
   ],
   "source": [
    "model_meta = {\n",
    "    client.repository.ModelMetaNames.AUTHOR_NAME: \"IBM\",\n",
    "    client.repository.ModelMetaNames.AUTHOR_EMAIL: \"ibm@ibm.com\",\n",
    "    client.repository.ModelMetaNames.NAME: \"cust_pyfunc_mnist\",\n",
    "    client.repository.ModelMetaNames.DESCRIPTION: \"cust MNIST with pyfunc\",\n",
    "    client.repository.ModelMetaNames.RUNTIME_UID: custom_runtime_uid,\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_NAME: \"tensorflow\",\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_VERSION: \"1.5\",\n",
    "    client.repository.ModelMetaNames.RUNTIME_NAME: \"python\",\n",
    "    client.repository.ModelMetaNames.RUNTIME_VERSION: \"3.5\"\n",
    "}\n",
    "model_details = client.repository.store_model(model=model_path, meta_props=model_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3e8db708-d8ca-4776-bafc-692e9dba50a6\n"
     ]
    }
   ],
   "source": [
    "model_uid = client.repository.get_model_uid(model_details)\n",
    "print(model_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity': {'author': {'name': 'IBM'},\n",
       "  'deployments': {'count': 0,\n",
       "   'url': 'https://us-south.ml.test.cloud.ibm.com/v3/wml_instances/abddf24b-62e3-4656-bd18-cdaad898b46f/published_models/3e8db708-d8ca-4776-bafc-692e9dba50a6/deployments'},\n",
       "  'description': 'cust MNIST with pyfunc',\n",
       "  'evaluation_metrics_url': 'https://us-south.ml.test.cloud.ibm.com/v3/wml_instances/abddf24b-62e3-4656-bd18-cdaad898b46f/published_models/3e8db708-d8ca-4776-bafc-692e9dba50a6/evaluation_metrics',\n",
       "  'feedback_url': 'https://us-south.ml.test.cloud.ibm.com/v3/wml_instances/abddf24b-62e3-4656-bd18-cdaad898b46f/published_models/3e8db708-d8ca-4776-bafc-692e9dba50a6/feedback',\n",
       "  'latest_version': {'created_at': '2019-06-11T11:19:37.084Z',\n",
       "   'guid': 'b39362d9-e99d-4936-aa7d-32dfa64ce38d',\n",
       "   'url': 'https://us-south.ml.test.cloud.ibm.com/v3/ml_assets/models/3e8db708-d8ca-4776-bafc-692e9dba50a6/versions/b39362d9-e99d-4936-aa7d-32dfa64ce38d'},\n",
       "  'learning_configuration_url': 'https://us-south.ml.test.cloud.ibm.com/v3/wml_instances/abddf24b-62e3-4656-bd18-cdaad898b46f/published_models/3e8db708-d8ca-4776-bafc-692e9dba50a6/learning_configuration',\n",
       "  'learning_iterations_url': 'https://us-south.ml.test.cloud.ibm.com/v3/wml_instances/abddf24b-62e3-4656-bd18-cdaad898b46f/published_models/3e8db708-d8ca-4776-bafc-692e9dba50a6/learning_iterations',\n",
       "  'model_type': 'tensorflow-1.5',\n",
       "  'name': 'cust_pyfunc_mnist',\n",
       "  'runtime': {'url': 'https://us-south.ml.test.cloud.ibm.com/v4/runtimes/a78603bc-f708-417d-9461-5a66d086c6bd'},\n",
       "  'runtime_environment': 'python-3.5'},\n",
       " 'metadata': {'created_at': '2019-06-11T11:19:37.023Z',\n",
       "  'guid': '3e8db708-d8ca-4776-bafc-692e9dba50a6',\n",
       "  'modified_at': '2019-06-11T11:19:37.084Z',\n",
       "  'url': 'https://us-south.ml.test.cloud.ibm.com/v3/wml_instances/abddf24b-62e3-4656-bd18-cdaad898b46f/published_models/3e8db708-d8ca-4776-bafc-692e9dba50a6'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Scoring'></a>\n",
    "## 8. Deploy and perform prediction on the Lenet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will deploy the saved model that uses the custom transformer and perform predictions. You will use WML client to perform these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: '3e8db708-d8ca-4776-bafc-692e9dba50a6' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "INITIALIZING\n",
      "DEPLOY_IN_PROGRESS..\n",
      "DEPLOY_SUCCESS\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_uid='c266ddfe-f913-4082-9dee-4b6170e64348'\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deployment_details = client.deployments.create(model_uid, \"Mnist model deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Score the deployed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the scoring url for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://us-south.ml.test.cloud.ibm.com/v3/wml_instances/abddf24b-62e3-4656-bd18-cdaad898b46f/deployments/c266ddfe-f913-4082-9dee-4b6170e64348/online\n"
     ]
    }
   ],
   "source": [
    "scoring_url = client.deployments.get_scoring_url(deployment_details)\n",
    "print(scoring_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare sample scoring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mnist.test.next_batch(1)[0].tolist()\n",
    "payload = {'values': image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x134fc0cf8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134e3db00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 1, 1)\n",
    "plt.axis('off')\n",
    "plt.imshow((np.reshape(np.array(image), (28, 28)) * 255).astype(np.uint8), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring result: [6]\n"
     ]
    }
   ],
   "source": [
    "predictions = client.deployments.score(scoring_url, payload)\n",
    "print('Scoring result: ' + str(predictions['values']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Delete the deployed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following method to delete the deployment when it is not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_id = client.deployments.get_uid(deployment_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.deployments.delete(deployment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we learnt how to create a custom python operation using Tensorflow's `tf.py_func` and used it on the LeNet model for MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also learnt how to use `watson-machine-learning-client` to store a library created for using the same operation into WML Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we stored our custom LeNet model with references to the created library into WML Repository which could be deployed and scored later using WML Service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore the functionalities of Watson Studio further, check out our [Online Documentation](https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html) for more samples, tutorials, documentation, how-tos, and blog posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "\n",
    "**Srikrishna S Bhat**, M. Tech, is a Software Engineer at IBM Watson Machine Learning Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
