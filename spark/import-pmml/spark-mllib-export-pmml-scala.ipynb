{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save a Spark MLlib model in PMML format\n",
    "\n",
    "This notebook demonstrates saving a trained Spark MLlib model in PMML format.\n",
    "\n",
    "This notebook runs on Spark Scala 2.11.\n",
    "\n",
    "\n",
    "## Notebook sections\n",
    "\n",
    "1. [Load and prepare training data](#loadata)\n",
    "2. [Train and evaluate model](#trainmodel)\n",
    "3. [Save model in PMML format](#savemodel)\n",
    "\n",
    "\n",
    "\n",
    "**About the sample model**\n",
    "\n",
    "The sample model built here is a logistic regression model for predicting whether or not a customer will purchase a tent from a fictional outdoor equipment store, based on the customer charateristics.\n",
    "\n",
    "The data used to train the model is the \"GoSales.csv\" training data in the IBM Watson Studio community: <a href=\"https://dataplatform.cloud.ibm.com/exchange/public/entry/view/aa07a773f71cf1172a349f33e2028e4e\" target=\"_blank\" rel=\"noopener noreferrer\">GoSales sample data</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"loaddata\"></a> 1. Load and prepare sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url = https://dataplatform.cloud.ibm.com/data/exchange-api/v1/entries/aa07a773f71cf1172a349f33e2028e4e/data?accessKey=e98b7315f84e5448aa94c633ca66ea83\n",
       "filename = GoSales.csv\n",
       "data = empty iterator\n",
       "data_file = java.io.FileWriter@18ce9481\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "java.io.FileWriter@18ce9481"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Download sample training data to notebook working directory\n",
    "import scala.io.Source\n",
    "import java.io.FileWriter\n",
    "val url = \"https://dataplatform.cloud.ibm.com/data/exchange-api/v1/entries/aa07a773f71cf1172a349f33e2028e4e/data?accessKey=e98b7315f84e5448aa94c633ca66ea83\"\n",
    "val filename = \"GoSales.csv\"\n",
    "val data = Source.fromURL( url )\n",
    "val data_file = new FileWriter( filename )\n",
    "data_file.write( data.mkString )\n",
    "data_file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GENDER: string (nullable = true)\n",
      " |-- AGE: integer (nullable = true)\n",
      " |-- MARITAL_STATUS: string (nullable = true)\n",
      " |-- PROFESSION: string (nullable = true)\n",
      " |-- IS_TENT: boolean (nullable = true)\n",
      " |-- PRODUCT_LINE: string (nullable = true)\n",
      " |-- PURCHASE_AMOUNT: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@6c1280e5\n",
       "df = [GENDER: string, AGE: int ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[GENDER: string, AGE: int ... 5 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Read sample data into a Spark DataFrame\n",
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder().getOrCreate()\n",
    "val df = spark.read\n",
    "    .format( \"org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\" )\n",
    "    .option( \"header\", \"true\" )\n",
    "    .option( \"inferSchema\", \"true\" )\n",
    "    .load( filename )\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GENDER: string (nullable = true)\n",
      " |-- AGE: integer (nullable = true)\n",
      " |-- MARITAL_STATUS: string (nullable = true)\n",
      " |-- PROFESSION: string (nullable = true)\n",
      " |-- IS_TENT: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "training_data = [GENDER: string, AGE: int ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[GENDER: string, AGE: int ... 3 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Select columns of interest\n",
    "// Convert the boolean label colum, IS_TENT, to an integer (0 or 1)\n",
    "val training_data  = df.selectExpr( \"GENDER\", \"AGE\", \"MARITAL_STATUS\", \"PROFESSION\", \"cast( IS_TENT as integer) IS_TENT\" )\n",
    "training_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indexer_GENDER = strIdx_30eeba0e60a9\n",
       "indexer_MARITAL_STATUS = strIdx_3bc6e6eff00d\n",
       "indexer_PROFESSION = strIdx_4168a53310ad\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "strIdx_4168a53310ad"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create indexers for string columns\n",
    "import org.apache.spark.ml.feature.StringIndexer\n",
    "val indexer_GENDER         = new StringIndexer().setInputCol( \"GENDER\" ).setOutputCol( \"GENDER_index\" ).fit( training_data )\n",
    "val indexer_MARITAL_STATUS = new StringIndexer().setInputCol( \"MARITAL_STATUS\" ).setOutputCol( \"MARITAL_STATUS_index\" ).fit( training_data )\n",
    "val indexer_PROFESSION     = new StringIndexer().setInputCol( \"PROFESSION\" ).setOutputCol( \"PROFESSION_index\" ).fit( training_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+--------------+------------+-------+------------+--------------------+----------------+\n",
      "|GENDER|AGE|MARITAL_STATUS|  PROFESSION|IS_TENT|GENDER_index|MARITAL_STATUS_index|PROFESSION_index|\n",
      "+------+---+--------------+------------+-------+------------+--------------------+----------------+\n",
      "|     M| 27|        Single|Professional|      1|         0.0|                 1.0|             1.0|\n",
      "|     F| 39|       Married|       Other|      0|         1.0|                 0.0|             0.0|\n",
      "|     F| 39|       Married|       Other|      0|         1.0|                 0.0|             0.0|\n",
      "|     F| 56|   Unspecified| Hospitality|      0|         1.0|                 2.0|             5.0|\n",
      "|     M| 45|       Married|     Retired|      0|         0.0|                 0.0|             8.0|\n",
      "+------+---+--------------+------------+-------+------------+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "training_data_2 = [GENDER: string, AGE: int ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[GENDER: string, AGE: int ... 6 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Add columns for the indexes strings\n",
    "val training_data_2 = indexer_PROFESSION.transform( indexer_MARITAL_STATUS.transform( indexer_GENDER.transform( training_data ) ) )\n",
    "training_data_2.show( 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|GENDER|GENDER_index|\n",
      "+------+------------+\n",
      "|     M|         0.0|\n",
      "|     F|         1.0|\n",
      "+------+------------+\n",
      "\n",
      "+--------------+--------------------+\n",
      "|MARITAL_STATUS|MARITAL_STATUS_index|\n",
      "+--------------+--------------------+\n",
      "|       Married|                 0.0|\n",
      "|        Single|                 1.0|\n",
      "|   Unspecified|                 2.0|\n",
      "+--------------+--------------------+\n",
      "\n",
      "+------------+----------------+\n",
      "|  PROFESSION|PROFESSION_index|\n",
      "+------------+----------------+\n",
      "|       Other|             0.0|\n",
      "|Professional|             1.0|\n",
      "|       Sales|             2.0|\n",
      "|   Executive|             3.0|\n",
      "|      Trades|             4.0|\n",
      "| Hospitality|             5.0|\n",
      "|     Student|             6.0|\n",
      "|      Retail|             7.0|\n",
      "|     Retired|             8.0|\n",
      "+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// For interest, view the mappings of string inputs to indexes\n",
    "import org.apache.spark.sql.functions._\n",
    "training_data_2.select( \"GENDER\", \"GENDER_index\" ).distinct().sort( asc( \"GENDER_index\" ) ).show\n",
    "training_data_2.select( \"MARITAL_STATUS\", \"MARITAL_STATUS_index\" ).distinct().sort( asc( \"MARITAL_STATUS_index\" ) ).show\n",
    "training_data_2.select( \"PROFESSION\", \"PROFESSION_index\" ).distinct().sort(  asc( \"PROFESSION_index\" ) ).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_vector_assembler = vecAssembler_8e1c0797b26d\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vecAssembler_8e1c0797b26d"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create an assembler that generates the feature vector column\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "val feature_vector_assembler = new VectorAssembler()\n",
    "  .setInputCols( Array( \"GENDER_index\", \"AGE\", \"MARITAL_STATUS_index\", \"PROFESSION_index\" ) )\n",
    "  .setOutputCol( \"features_vector\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+--------------+------------+-------+------------+--------------------+----------------+------------------+\n",
      "|GENDER|AGE|MARITAL_STATUS|  PROFESSION|IS_TENT|GENDER_index|MARITAL_STATUS_index|PROFESSION_index|   features_vector|\n",
      "+------+---+--------------+------------+-------+------------+--------------------+----------------+------------------+\n",
      "|     M| 27|        Single|Professional|      1|         0.0|                 1.0|             1.0|[0.0,27.0,1.0,1.0]|\n",
      "|     F| 39|       Married|       Other|      0|         1.0|                 0.0|             0.0|[1.0,39.0,0.0,0.0]|\n",
      "|     F| 39|       Married|       Other|      0|         1.0|                 0.0|             0.0|[1.0,39.0,0.0,0.0]|\n",
      "|     F| 56|   Unspecified| Hospitality|      0|         1.0|                 2.0|             5.0|[1.0,56.0,2.0,5.0]|\n",
      "|     M| 45|       Married|     Retired|      0|         0.0|                 0.0|             8.0|[0.0,45.0,0.0,8.0]|\n",
      "+------+---+--------------+------------+-------+------------+--------------------+----------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "training_data_3 = [GENDER: string, AGE: int ... 7 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[GENDER: string, AGE: int ... 7 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Update the training data to add the feature vector column\n",
    "val training_data_3 = feature_vector_assembler.transform( training_data_2 )\n",
    "training_data_3.show( 5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"trainmodel\"></a> 2. Create a logistic regression model and then train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lr = logreg_eeae090a6c13\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "logreg_eeae090a6c13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create a logistic regression model\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "val lr = new LogisticRegression()\n",
    "  .setFeaturesCol( \"features_vector\" )\n",
    "  .setLabelCol( \"IS_TENT\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count: 45186\n",
      "Test count: 15066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "splits = Array([GENDER: string, AGE: int ... 7 more fields], [GENDER: string, AGE: int ... 7 more fields])\n",
       "train = [GENDER: string, AGE: int ... 7 more fields]\n",
       "test = [GENDER: string, AGE: int ... 7 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[GENDER: string, AGE: int ... 7 more fields]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Split the training data into a training set and a test set\n",
    "val splits = training_data_3.randomSplit( Array( 0.75, 0.25 ), seed = 2019 )\n",
    "val train = splits( 0 ).cache()\n",
    "val test = splits( 1 )\n",
    "println( \"Train count: \" + train.count() )\n",
    "println( \"Test count: \"  + test.count()  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-1.6691109760782625,-0.13800412307651586,-0.24480344066228285,0.22211090608184475] Intercept: 3.5810705512843337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lr_model = logreg_eeae090a6c13\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "logreg_eeae090a6c13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Train the model\n",
    "val lr_model = lr.fit( train )\n",
    "println( s\"Coefficients: ${lr_model.coefficients} Intercept: ${lr_model.intercept}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 78%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictions = [GENDER: string, AGE: int ... 10 more fields]\n",
       "correct_false = [GENDER: string, AGE: int ... 4 more fields]\n",
       "correct_true = [GENDER: string, AGE: int ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[GENDER: string, AGE: int ... 4 more fields]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Evaluate the model performance\n",
    "val predictions = lr_model.transform( test )\n",
    "val correct_false = predictions\n",
    "  .filter( \"IS_TENT == 0 AND prediction == 0.0\" )\n",
    "  .select( \"GENDER\", \"AGE\", \"MARITAL_STATUS\", \"PROFESSION\", \"IS_TENT\", \"prediction\" )\n",
    "val correct_true = predictions\n",
    "  .filter( \"IS_TENT == 1 AND prediction != 0.0\" )\n",
    "  .select( \"GENDER\", \"AGE\", \"MARITAL_STATUS\", \"PROFESSION\", \"IS_TENT\", \"prediction\" )\n",
    "println( \"Success rate: \" + Math.round( 100 * ( correct_false.count() + correct_true.count() ).toFloat / predictions.count() ) + \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer who did not buy a tent:\n",
      "[F,35,Married,Professional,0,1.0,0.0,1.0,[1.0,35.0,0.0,1.0]]\n",
      "\n",
      "Customer who did buy a tent:\n",
      " [M,20,Single,Sales,1,0.0,1.0,2.0,[0.0,20.0,1.0,2.0]]\n"
     ]
    }
   ],
   "source": [
    "// Grab some example data for quick test\n",
    "println( \"Customer who did not buy a tent:\\n\" + training_data_3.rdd.take(14).last )\n",
    "println( \"\\nCustomer who did buy a tent:\\n \" + training_data_3.rdd.take(15).last )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class Customer\n",
       "negative_example_payload = [features_vector: vector]\n",
       "positive_example_payload = [features_vector: vector]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[features_vector: vector]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.linalg.Vector\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "import spark.implicits._\n",
    "case class Customer( features_vector: org.apache.spark.ml.linalg.Vector )\n",
    "val negative_example_payload = Seq( Customer( Vectors.dense(1.0, 35.0, 0.0, 1.0) ) ).toDS()\n",
    "val positive_example_payload = Seq( Customer( Vectors.dense(0.0, 20.0, 1.0, 2.0) ) ).toDS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       0.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model.transform( negative_example_payload ).select( \"prediction\" ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       1.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model.transform( positive_example_payload ).select( \"prediction\" ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"savemodel\"></a> 3. Save the model in PMML format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lr_mllib = org.apache.spark.mllib.classification.LogisticRegressionModel: intercept = 3.5810705512843337, numFeatures = 4, numClasses = 2, threshold = 0.5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.mllib.classification.LogisticRegressionModel: intercept = 3.5810705512843337, numFeatures = 4, numClasses = 2, threshold = 0.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create an org.apache.spark.mllib.classification.LogisticRegressionModel object\n",
    "import org.apache.spark.mllib.classification.LogisticRegressionModel\n",
    "import org.apache.spark.mllib.linalg.Vectors\n",
    "val lr_mllib = new LogisticRegressionModel( org.apache.spark.mllib.linalg.Vectors.dense( lr_model.coefficients.toArray ), lr_model.intercept )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Save the model to a file in PMML format\n",
    "lr_mllib.toPMML( \"spark-mllib-lr-model-pmml.xml\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::::::::::::::\n",
      "spark-mllib-lr-model-pmml.xml\n",
      "::::::::::::::\n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n",
      "<PMML xmlns=\"http://www.dmg.org/PMML-4_2\" version=\"4.2\">\n",
      "    <Header description=\"logistic regression\">\n",
      "        <Application name=\"Apache Spark MLlib\" version=\"2.3.0\"/>\n",
      "        <Timestamp>2019-01-12T21:42:18</Timestamp>\n",
      "    </Header>\n",
      "    <DataDictionary numberOfFields=\"5\">\n",
      "        <DataField name=\"field_0\" optype=\"continuous\" dataType=\"double\"/>\n",
      "        <DataField name=\"field_1\" optype=\"continuous\" dataType=\"double\"/>\n",
      "        <DataField name=\"field_2\" optype=\"continuous\" dataType=\"double\"/>\n",
      "        <DataField name=\"field_3\" optype=\"continuous\" dataType=\"double\"/>\n",
      "        <DataField name=\"target\" optype=\"categorical\" dataType=\"string\"/>\n",
      "    </DataDictionary>\n",
      "    <RegressionModel modelName=\"logistic regression\" functionName=\"classification\" normalizationMethod=\"logit\">\n",
      "        <MiningSchema>\n",
      "            <MiningField name=\"field_0\" usageType=\"active\"/>\n",
      "            <MiningField name=\"field_1\" usageType=\"active\"/>\n",
      "            <MiningField name=\"field_2\" usageType=\"active\"/>\n",
      "            <MiningField name=\"field_3\" usageType=\"active\"/>\n",
      "            <MiningField name=\"target\" usageType=\"target\"/>\n",
      "        </MiningSchema>\n",
      "        <RegressionTable intercept=\"3.5810705512843337\" targetCategory=\"1\">\n",
      "            <NumericPredictor name=\"field_0\" coefficient=\"-1.6691109760782625\"/>\n",
      "            <NumericPredictor name=\"field_1\" coefficient=\"-0.13800412307651586\"/>\n",
      "            <NumericPredictor name=\"field_2\" coefficient=\"-0.24480344066228285\"/>\n",
      "            <NumericPredictor name=\"field_3\" coefficient=\"0.22211090608184475\"/>\n",
      "        </RegressionTable>\n",
      "        <RegressionTable intercept=\"-0.0\" targetCategory=\"0\"/>\n",
      "    </RegressionModel>\n",
      "</PMML>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one feature warning; re-run with -feature for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys.process._\n",
    "\"more spark-mllib-lr-model-pmml.xml\" !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**\n",
    "\n",
    "You can use your mouse to highlight-copy the PMML content from running the previous cell, then paste the content into a text editor on your local computer, and then save the file on your local computer as \"spark-mllib-lr-model-pmml.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and next steps\n",
    "In this notebook, you created a logistic regression model using Spark MLlib and then saved the model to a file in PMML format.\n",
    "\n",
    "To learn how you can import this model into Watson Machine Learning, see:\n",
    "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/analyze-data/ml-import-pmml.html\" target=\"_blank\" rel=\"noopener noreferrer\">Importing models into Watson Machine Learning from PMML</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"authors\"></a>Authors\n",
    "\n",
    "**Sarah Packowski** is a member of the IBM Watson Studio Content Design team in Canada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr>\n",
    "Copyright &copy; IBM Corp. 2019. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n",
    "<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n",
    "<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
